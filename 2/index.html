<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Project 2 — Fun with Filters & Frequencies (CS180)</title>
  <meta name="description" content="Convolutions from scratch, finite differences, DoG, unsharp masking, hybrid images, and multiresolution blending." />
  <style>
    :root{
      --bg:#f5f9ff; --ink:#0e1b2c; --muted:#5a6b82;
      --accent:#3b82f6; --accent-2:#60a5fa;
      --card:#ffffff; --border:#e6edf7;
      --shadow:0 10px 25px rgba(25,74,142,.12);
      --radius:18px; --max:1080px;
    }
    html,body{background:var(--bg); color:var(--ink); font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Noto Sans, "Helvetica Neue", Arial}
    body{margin:0; padding:28px 18px 56px}
    .wrap{max-width:var(--max); margin:0 auto}
    a{color:var(--accent); text-decoration:none}
    header{margin-bottom:1rem}
    h1{font-size:clamp(1.6rem, 1.15rem + 2vw, 2.4rem); line-height:1.15; margin:.25rem 0}
    .pill{display:inline-block; padding:.25rem .6rem; border-radius:999px; border:1px solid rgba(59,130,246,.25); background:rgba(59,130,246,.12); color:#0b3a7a; font-weight:600; font-size:.85rem}
    .card{background:var(--card); border:1px solid var(--border); border-radius:var(--radius); padding:18px; box-shadow:var(--shadow); margin:18px 0}
    .grid{display:grid; gap:14px}
    .two{grid-template-columns:1fr}
    .three{grid-template-columns:1fr}
    @media(min-width:780px){ .two{grid-template-columns:1fr 1fr} .three{grid-template-columns:1fr 1fr 1fr} }
    figure{margin:0}
    img{width:100%; height:auto; display:block; border-radius:14px; border:1px solid var(--border)}
    figcaption{margin-top:.4rem; color:var(--muted); font-size:.95rem}
    h2{margin:.25rem 0 .65rem; font-size:1.3rem}
    h3{margin:.25rem 0 .4rem; font-size:1.05rem}
    .why{border-left:3px solid var(--accent); padding:.5rem .75rem; background:rgba(59,130,246,.06); border-radius:.5rem}
    .hr{height:1px; background:var(--border); margin:1.5rem 0}
    footer{margin-top:2rem; color:var(--muted); font-size:.95rem}
    .kbd{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace; background:#eef4ff; border:1px solid #d7e5ff; padding:2px 6px; border-radius:6px}
    code{background:#f3f6ff; border:1px solid #e6edf7; padding:.1rem .3rem; border-radius:6px}
    @media print{ body{padding:0; background:#fff} .card{box-shadow:none} a[href]:after{content:""} }
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <a href="/">← Back to Home</a>
      <h1>Project 2 — Fun with Filters & Frequencies</h1>
      <span class="pill">CS180</span>
    </header>

    <div class="card">
      <p>This page includes all required deliverables (no bells & whistles). Code that generated these figures is in <code>/code</code> in my GitHub repo.</p>
      <p class="why"><strong>Submission tip:</strong> Print this page to PDF with <span class="kbd">Background graphics</span> enabled (Chrome: Print → More settings).</p>
    </div>

    <!-- =========================
         PART 1 — FILTERS & EDGES
         ========================= -->
    <section class="card" id="part1-1">
      <h2>Part 1.1 — Convolutions from Scratch</h2>
      <p>I implemented 2D convolution with zero padding in two ways: a 4-loop (explicit multiply-accumulate) and a 2-loop (windowed dot-product). I also compare to SciPy’s <code>convolve2d</code>. Below are a 9×9 box-filtered result using each method and the reference.</p>
      <div class="grid three">
        <figure><img src="media/01_original.png" alt="Original"><figcaption>Original (grayscale selfie)</figcaption></figure>
        <figure><img src="media/02_box_filter_4loop.png" alt="Box filter 4-loop"><figcaption>9×9 box — 4 loops</figcaption></figure>
        <figure><img src="media/03_box_filter_2loop.png" alt="Box filter 2-loop"><figcaption>9×9 box — 2 loops</figcaption></figure>
      </div>
      <div class="grid two" style="margin-top:.8rem">
        <figure><img src="media/06_result_scipy.png" alt="SciPy convolve2d"><figcaption>Reference: SciPy <code>convolve2d</code></figcaption></figure>
        <div class="why">
          <p><strong>Runtime & boundaries:</strong> The 2-loop version is faster because it uses vectorized dot-products over each window. Both custom methods use <em>zero padding</em>, so borders appear slightly darker due to missing context; SciPy with <code>mode='same'</code> under default zero boundary matches that behavior.</p>
        </div>
      </div>
      <h3 style="margin-top:1rem">Finite differences Dx/Dy (same implementation)</h3>
      <div class="grid two">
        <figure><img src="media/04_dx_edges.png" alt="Dx edges"><figcaption>Dx (horizontal derivative)</figcaption></figure>
        <figure><img src="media/05_dy_edges.png" alt="Dy edges"><figcaption>Dy (vertical derivative)</figcaption></figure>
      </div>
    </section>

    <section class="card" id="part1-2">
      <h2>Part 1.2 — Finite Difference Operator</h2>
      <p>On the “Cameraman” image, I compute partial derivatives, gradient magnitude, then binarize with a threshold.</p>
      <div class="grid three">
        <figure><img src="media/07_cameraman_original.png" alt="Cameraman"><figcaption>Original</figcaption></figure>
        <figure><img src="media/08_gradient_x.png" alt="Grad X"><figcaption>∂I/∂x</figcaption></figure>
        <figure><img src="media/09_gradient_y.png" alt="Grad Y"><figcaption>∂I/∂y</figcaption></figure>
      </div>
      <div class="grid two" style="margin-top:.8rem">
        <figure><img src="media/10_gradient_magnitude.png" alt="‖∇I‖"><figcaption>‖∇I‖</figcaption></figure>
        <figure><img src="media/11_edge_image.png" alt="Edges"><figcaption>Edges (threshold = 100)</figcaption></figure>
      </div>
      <div class="why" style="margin-top:.8rem">
        <strong>Threshold choice:</strong> I picked 100 to suppress noise while keeping salient object boundaries. Lower values revealed thin noise edges; higher values began dropping true contours. The chosen value balances completeness and cleanliness qualitatively.
      </div>
    </section>

    <section class="card" id="part1-3">
      <h2>Part 1.3 — Derivative of Gaussian (DoG)</h2>
      <p>First smooth with a Gaussian, then differentiate; alternatively convolve the Gaussian with Dx/Dy once to create DoG filters and apply them. These two routes match (up to tiny numerical differences).</p>
      <div class="grid three">
        <figure><img src="media/12_gaussian_kernel.png" alt="Gaussian kernel viz"><figcaption>Gaussian kernel (viz)</figcaption></figure>
        <figure><img src="media/13_smoothed_cameraman.png" alt="Smoothed"><figcaption>Smoothed image</figcaption></figure>
        <figure><img src="media/16_smooth_gradient_magnitude.png" alt="Smoothed grad magnitude"><figcaption>‖∇(G*I)‖</figcaption></figure>
      </div>
      <div class="grid three" style="margin-top:.8rem">
        <figure><img src="media/18_dog_x_filter.png" alt="DoGx"><figcaption>DoG<sub>x</sub> = G * Dx</figcaption></figure>
        <figure><img src="media/19_dog_y_filter.png" alt="DoGy"><figcaption>DoG<sub>y</sub> = G * Dy</figcaption></figure>
        <figure><img src="media/23_dog_edge_image.png" alt="DoG edges"><figcaption>Edges via DoG</figcaption></figure>
      </div>
      <div class="why" style="margin-top:.8rem">
        <strong>Comparison to finite differences:</strong> DoG reduces spurious noise and produces cleaner, thicker edges because smoothing suppresses high-frequency noise before differentiation.
      </div>
    </section>

    <div class="hr"></div>

    <!-- =========================
         PART 2 — APPLICATIONS
         ========================= -->
    <section class="card" id="part2-1">
      <h2>Part 2.1 — Image “Sharpening” (Unsharp Mask)</h2>
      <p><em>Unsharp mask</em> adds scaled high frequencies back to the image: <code>sharp = img + amount · (img − blur(img))</code>.</p>
      <h3>Taj Mahal</h3>
      <div class="grid two">
        <figure><img src="media/24_taj_original.png" alt="Taj original"><figcaption>Original</figcaption></figure>
        <figure><img src="media/27_taj_sharpened.png" alt="Taj sharpened"><figcaption>Sharpened (amount=1.0)</figcaption></figure>
      </div>
      <div class="grid two" style="margin-top:.8rem">
        <figure><img src="media/25_taj_blurred.png" alt="Taj blurred"><figcaption>Low-pass (blurred)</figcaption></figure>
        <figure><img src="media/26_taj_high_freq.png" alt="Taj high freq"><figcaption>High frequencies (img − blur)</figcaption></figure>
      </div>
      <h3 style="margin-top:1rem">Additional examples</h3>
      <div class="grid three">
        <figure><img src="media/28_fren_original.png" alt="Blurry"><figcaption>Blurry original</figcaption></figure>
        <figure><img src="media/31_fren_sharpened.png" alt="Blurry sharpened"><figcaption>Sharpened (amount=5.0)</figcaption></figure>
        <figure><img src="media/35_lake_sharpened.png" alt="Lake sharpened"><figcaption>Sharpened (amount=1.0)</figcaption></figure>
      </div>
      <div class="why" style="margin-top:.8rem">
        <strong>Observation:</strong> On naturally sharp images, small amounts improve crispness; too large an amount introduces halos/noise. On blurry images, larger amounts help but can amplify sensor noise and ringing.
      </div>
    </section>

    <section class="card" id="part2-2">
      <h2>Part 2.2 — Hybrid Images</h2>
      <p>Low-pass one image, high-pass another, then add. Close-up vision is dominated by high frequencies; at a distance, low frequencies dominate.</p>
      <h3>Derek + Nutmeg (full process)</h3>
      <div class="grid three">
        <figure><img src="media/36_derek_aligned.png" alt="Derek aligned"><figcaption>High-freq source (aligned)</figcaption></figure>
        <figure><img src="media/37_nutmeg_aligned.png" alt="Nutmeg aligned"><figcaption>Low-freq source (aligned)</figcaption></figure>
        <figure><img src="media/38_derek_nutmeg_hybrid.png" alt="Hybrid result"><figcaption>Hybrid result</figcaption></figure>
      </div>
      <div class="grid three" style="margin-top:.8rem">
        <figure><img src="media/39_derek_low_freq.png" alt="Low freq"><figcaption>Low-pass(A)</figcaption></figure>
        <figure><img src="media/40_nutmeg_high_freq.png" alt="High freq"><figcaption>High-pass(B)</figcaption></figure>
        <figure><img src="media/43_fft_derek_nutmeg_hybrid.png" alt="FFT hybrid"><figcaption>FFT log-magnitude (hybrid)</figcaption></figure>
      </div>
      <div class="why" style="margin-top:.8rem">
        <strong>Cutoff choices:</strong> I tuned Gaussian σ for a clear high/low split while keeping good facial alignment. Too small σ leaves both images sharp (muddy hybrid); too large σ over-smooths the low-pass and weakens the effect.
      </div>

      <h3 style="margin-top:1rem">Two more hybrids</h3>
      <div class="grid two">
        <figure><img src="media/48_fuji_wi_hybrid.png" alt="Hybrid 2"><figcaption>Hybrid #2</figcaption></figure>
        <figure><img src="media/51_alan_deer_hybrid.png" alt="Hybrid 3"><figcaption>Hybrid #3</figcaption></figure>
      </div>
    </section>

    <section class="card" id="part2-3-2-4">
      <h2>Part 2.3 + 2.4 — Gaussian/Laplacian Stacks & Multiresolution Blending</h2>
      <p>I build Gaussian stacks (no downsampling) and Laplacian stacks (band-pass) for each image, plus a Gaussian stack for the mask; then blend Laplacians per level and reconstruct.</p>
      <h3>Oraple (Apple + Orange)</h3>
      <div class="grid three">
        <figure><img src="media/55_apple.png" alt="Apple"><figcaption>Apple</figcaption></figure>
        <figure><img src="media/56_orange.png" alt="Orange"><figcaption>Orange</figcaption></figure>
        <figure><img src="media/57_oraple.png" alt="Oraple"><figcaption>Blended result</figcaption></figure>
      </div>
      <figure style="margin-top:.8rem">
        <img src="media/58_oraple_stacks.png" alt="Stacks visualization">
        <figcaption>Laplacian stacks per level (A, B, blended).</figcaption>
      </figure>

      <h3 style="margin-top:1rem">Two additional custom blends</h3>
      <div class="grid two">
        <figure><img src="media/61_wi_fuji.png" alt="WI+Fuji"><figcaption>Vertical seam blend</figcaption></figure>
        <figure><img src="media/65_alan_deer_ellipse_mask.png" alt="Irregular mask blend"><figcaption>Blend with irregular mask</figcaption></figure>
      </div>
      <div class="why" style="margin-top:.8rem">
        <strong>Parameters:</strong> 6 levels, Gaussian σ≈2 per level. A Gaussian mask stack smooths transitions so seams are not visible. More levels or slightly larger σ can further soften seams.
      </div>
    </section>

    <section class="card" id="reflection">
      <h2>Most Important Thing I Learned</h2>
      <p>Separating and controlling frequency bands is a powerful unifying idea: the same Gaussian/Laplacian machinery explains smoothing, sharpening, edge detection (via DoG), perception in hybrids, and seamless blending.</p>
    </section>

    <footer>
      <div class="hr"></div>
      <p>© <span id="year"></span> Raymond Wang • <a href="https://raymond23101.github.io">raymond23101.github.io</a></p>
    </footer>
  </div>
  <script>document.getElementById('year').textContent = new Date().getFullYear();</script>
</body>
</html>
